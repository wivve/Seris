{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d461d58-a358-4e61-a5bb-ca3bd0806b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import torch.nn as nn\n",
    "import polars as pr\n",
    "import plotly.express as ex\n",
    "\n",
    "from torch import Tensor\n",
    "from random import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from polars.dataframe.frame import DataFrame\n",
    "from polars.series.series import Series\n",
    "from typing import Optional, Dict, List, NoReturn, Callable, Generic, Any\n",
    "\n",
    "import seris\n",
    "import os\n",
    "torch.set_default_device(\"cuda:0\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7108f655-bbf2-401a-b0ad-92679e6b91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.getenv(\"HOME\")\n",
    "train1 = HOME + \"/Datasets/muld_OpenSubtitles/data/train-00000-of-00003-ae10b8591df9b61f.parquet\"\n",
    "train2 = HOME + \"/Datasets/muld_OpenSubtitles/data/train-00001-of-00003-d297e02053936096.parquet\"\n",
    "train3 = HOME + \"/Datasets/muld_OpenSubtitles/data/train-00002-of-00003-7c2c5fa1d6ac9938.parquet\"\n",
    "test = HOME + \"/Datasets/muld_OpenSubtitles/data/test-00000-of-00001-30e0e85c508944e5.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fbc833c-e494-452c-a8a0-032f0724b4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9250"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = seris.SimpleDataset(train1)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64c5cdaf-de44-46a0-bd39-c5f90c485939",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = seris.dataset.GetData(dataset[0])\n",
    "# chunk[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85f0102-bc49-48fa-a054-04aeb91b6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.k_proj = nn.Linear(d_model , d_model)\n",
    "        self.q_proj = nn.Linear(d_model , d_model)\n",
    "        self.v_proj = nn.Linear(d_model , d_model)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        k: Tensor = self.k_proj(x)\n",
    "        q: Tensor = self.q_proj(x)\n",
    "        v: Tensor = self.v_proj(x)\n",
    "        return nn.functional.softmax((k@q.transpose(-1,-2)).div(self.d_model),dim=-1)@v\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim :int = 64,\n",
    "        d_model : int = 64,\n",
    "        nheads : int = 1\n",
    "    ):\n",
    "        assert dim%nheads == 0\n",
    "        super().__init__()\n",
    "        self.nheads = nheads\n",
    "        self.head_dim = dim//nheads\n",
    "        self.heads = nn.ModuleList([Attention(d_model=d_model) for _ in range(nheads)])\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = einops.rearrange(x , 'b (t c) d -> b t c d' , t=self.nheads)\n",
    "        x = torch.concat(tuple(head(x[:,i,:]) for i,head in enumerate(self.heads,start=0)),dim=-2)\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,*,\n",
    "        dim: int = 64,\n",
    "        nheads: int = 1,\n",
    "        d_model: int =32,\n",
    "        vocab_size: int = 1,\n",
    "        batch_size: int = 32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.nheads = nheads\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.bs = batch_size\n",
    "        self.emb_proj = nn.Embedding(vocab_size, d_model)\n",
    "        self.multihead = Head( dim = dim ,d_model=d_model , nheads=nheads)\n",
    "        self.fully_conn = nn.Sequential(\n",
    "            nn.Linear(d_model*dim , vocab_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.emb_proj( x )\n",
    "        x = self.multihead( x )\n",
    "        x = self.fully_conn( x.view(-1, self.d_model*self.dim) )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74532fbb-f7bc-4669-946e-5c43b443e0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = seris.Tokenizer(special_token= [\"<reserved_1>\",\"<reserved_2>\" ,\"<end>\",\"<start>\"] )\n",
    "for i in dataset:\n",
    "    tk.train(i)\n",
    "tk.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38feb831-ff84-4790-aad8-ddaf4c30f978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 398, 397, 398)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk.kv.keys()) ,\\\n",
    "len(tk.vk.keys()) ,\\\n",
    "max(tk.kv.values()) ,\\\n",
    "tk.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b61cc1-c989-4584-b1cd-81d8eaf3e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_rand(tensor_data:Tensor, batch_size=32, dim=64):\n",
    "    # ( batchsize*32 , ( input*64 ) )  , ( batchsize*32 , ( output*1 ))\n",
    "    l = len(tensor_data) -1\n",
    "    rnd = torch.randint( l-dim ,(batch_size,))\n",
    "    x = torch.concat( [ tensor_data[i:i+dim].unsqueeze(0) for i in rnd ] ,dim=0)\n",
    "    y = torch.concat( [ tensor_data[i+dim].unsqueeze(0) for i in rnd ] ,dim=0)\n",
    "    return x,y\n",
    "\n",
    "def get_batch(tensor_data:Tensor, batch_size=32, dim=64):\n",
    "    # ( batchsize*32 , ( input*64 ) )  , ( batchsize*32 , ( output*1 ))\n",
    "    length = len(tensor_data) -batch_size\n",
    "    for i in range(length-dim):\n",
    "        lst = list(range(i,i+batch_size))\n",
    "        x_ = torch.concat( [ tensor_data[i:i+dim].unsqueeze(0) for i in lst ] ,dim=0)\n",
    "        y_ = torch.concat( [ tensor_data[i+dim].unsqueeze(0) for i in lst ] ,dim=0)\n",
    "        yield x_,y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1af0c-72fc-46d3-bf20-424b86172877",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0e-3\n",
    "dim = 32\n",
    "batch_size = 64\n",
    "nheads = 2\n",
    "d_model = 32\n",
    "vocab_size = tk.vocab_size\n",
    "\n",
    "net = Transformer(\n",
    "    batch_size=batch_size,\n",
    "    d_model=d_model,\n",
    "    dim=dim,\n",
    "    nheads=nheads,\n",
    "    vocab_size=vocab_size\n",
    ")\n",
    "optim = torch.optim.AdamW(params=net.parameters(),lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for corpus in dataset:\n",
    "    for x,y in get_batch(tk.encode(corpus),batch_size=batch_size,dim=dim):\n",
    "        y_ = net(x)\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(y_,y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
